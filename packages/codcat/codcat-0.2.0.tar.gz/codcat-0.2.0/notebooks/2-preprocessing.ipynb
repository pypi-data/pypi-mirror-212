{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a229ab-0591-4f49-9dfb-27a6f0d19b46",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7a83f-30da-48c4-a287-b1245e2259a0",
   "metadata": {},
   "source": [
    "Source code preprocessing has several features:\n",
    "\n",
    "1) Each language has its own grammar.\n",
    "When working with source code, lexemes are usually individual words or code elements, such as variable names, function names, and operator names.\n",
    "2) Source code preprocessing also requires certain steps that are unique to code, such as removing code comments, handling variable declarations and imports, and dealing with the peculiarities of coding languages.\n",
    "\n",
    "For now we will choose `TweetTokenizer`, in the future we will describe the preprocessing with `code_tokenize` (tree-sitter) packets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f75909f-d27e-4aa2-bf47-be152a50f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NLTKWordTokenizer, TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bd0766-7400-4573-addb-a4ee29ed6cae",
   "metadata": {},
   "source": [
    "Removing some tokens (e.g., a string literal or a number) must be done at the tokenization stage, since only at this point do we know the types of tokens.\n",
    "\n",
    "So in the following example, using `tokenize` removes `'bar'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "079b3bbd-afad-4546-b83b-8ee02d9d6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "def foo(bar: int) -> dict:\n",
    "    return {'bar': bar}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e855757-9dad-4241-8af8-06753d009a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def foo ( bar : int ) - > dict : return { 'bar ' : bar }\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(NLTKWordTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20643b4d-006d-4e07-a021-301259dd796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def foo ( bar : int ) -> dict : return { ' bar ' : bar }\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(TweetTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5431c320-34ef-4a95-905b-4066f9b573d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int main() { double n1, n2, n3; cout << \"Hello, world!\"; }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b09847e1-3595-4c40-bff1-72678d7bf559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# include < iostream > using namespace std ; int main ( ) { double n1 , n2 , n3 ; cout < < `` Hello , world ! '' ; }\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(NLTKWordTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dd3cc3-3556-460f-983d-5f6db7f764c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#include <iostream> using namespace std ; int main ( ) { double n1 , n2 , n3 ; cout < < \" Hello , world ! \" ; }'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(TweetTokenizer().tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f9df5e-7c18-47ed-b1b2-3408bd601494",
   "metadata": {},
   "source": [
    "## Save preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca5abbb4-a63f-43f9-aab5-bf7fa21902a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa90cf81-53ba-4f61-ad85-243e63adb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c380dca7-1afb-4e10-85f9-9c2c9ee125f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c154f5-ee0e-4628-afcb-a559def89941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c50442f-a6ab-42b7-97ac-a9f3bc09c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['code'] = train.apply(lambda x: ' '.join(tokenizer.tokenize(x['code'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185abfb9-f70a-4a01-8d3c-ef2de0d5b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['code'] = test.apply(lambda x: ' '.join(tokenizer.tokenize(x['code'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ab49ab2-41e1-44c0-90fb-b53c878ce1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['code'] = train['code'].apply(lambda x: x.lower().strip())\n",
    "test['code'] = test['code'].apply(lambda x: x.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d265136-8c3f-4bc6-bf87-da62ff7db98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96028/1269989916.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  test = test[(test['code'].map(len) > 0) & (train['code'] != 'null')]\n"
     ]
    }
   ],
   "source": [
    "train = train[(train['code'].map(len) > 0) & (train['code'] != 'null')]\n",
    "test = test[(test['code'].map(len) > 0) & (train['code'] != 'null')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c0fb5c-e982-4314-9946-496d740a0d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train-preprocessed.csv', index=None)\n",
    "test.to_csv('test-preprocessed.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
