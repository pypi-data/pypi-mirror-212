{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8b9f329-5871-4a82-baaf-762fc55890a4",
   "metadata": {},
   "source": [
    "## Bag of words & TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd6e09b-214e-438a-9683-a717d7d83e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1181b663-8714-4b3a-98a3-5400c308a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train-preprocessed.csv')\n",
    "test = pd.read_csv('test-preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc182414-98ee-4b87-aff0-0468810a0ace",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "In this notebook I will do a little analysis of `Bag of Words`, `TF-IDF` with tokenization by words (by default) and with space-separated tokenization (because the pre-processed data contain exactly tokens with space-separated tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef97f5df-f9f3-4ff3-9076-f3e8c8ad15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c0e8b6-87e4-4510-a210-6790c1151d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['language']\n",
    "y_test = test['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1499d85-9c10-4704-a9f7-5192877e9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_df=0.7, min_df=0.003)\n",
    "vectorizer_split = CountVectorizer(max_df=0.7, min_df=0.003, tokenizer=lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e55aefef-b18f-45ce-8c2e-5933cd0a9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(train['code'])\n",
    "X_test_vectorized = vectorizer.transform(test['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b2af68-cf4a-4831-af58-b945af1e94f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.84      0.93      0.89       229\n",
      "         cpp       0.87      0.85      0.86       230\n",
      "         css       0.92      0.96      0.94       220\n",
      "     haskell       0.91      0.87      0.89       221\n",
      "        html       0.88      0.84      0.86       240\n",
      "        java       0.95      0.96      0.96       216\n",
      "  javascript       0.84      0.90      0.87       219\n",
      "         lua       0.93      0.88      0.90       218\n",
      "        objc       0.95      0.92      0.94       243\n",
      "        perl       0.90      0.93      0.92       225\n",
      "         php       0.76      0.80      0.78       237\n",
      "      python       0.95      0.88      0.91       225\n",
      "           r       0.89      0.87      0.88       214\n",
      "        ruby       0.95      0.80      0.87       208\n",
      "       scala       0.88      0.95      0.92       198\n",
      "      sqlite       0.94      0.96      0.95       209\n",
      "       swift       0.93      0.95      0.94       210\n",
      "\n",
      "    accuracy                           0.90      3762\n",
      "   macro avg       0.90      0.90      0.90      3762\n",
      "weighted avg       0.90      0.90      0.90      3762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB().fit(X_train_vectorized, y_train)\n",
    "preds = mnb.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a87671-ede2-4d09-b931-c8beb92a8100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qnbhd/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.84      0.99      0.91       229\n",
      "         cpp       0.96      0.85      0.90       230\n",
      "         css       0.96      0.94      0.95       220\n",
      "     haskell       0.91      0.90      0.90       221\n",
      "        html       0.89      0.93      0.91       240\n",
      "        java       0.94      0.95      0.95       216\n",
      "  javascript       0.89      0.93      0.91       219\n",
      "         lua       0.94      0.93      0.94       218\n",
      "        objc       0.99      0.96      0.97       243\n",
      "        perl       0.94      0.96      0.95       225\n",
      "         php       0.92      0.94      0.93       237\n",
      "      python       0.92      0.89      0.91       225\n",
      "           r       0.90      0.93      0.92       214\n",
      "        ruby       0.95      0.84      0.89       208\n",
      "       scala       0.90      0.94      0.92       198\n",
      "      sqlite       0.97      0.93      0.95       209\n",
      "       swift       1.00      0.96      0.98       210\n",
      "\n",
      "    accuracy                           0.93      3762\n",
      "   macro avg       0.93      0.93      0.93      3762\n",
      "weighted avg       0.93      0.93      0.93      3762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vectorizer_split.fit_transform(train['code'])\n",
    "X_test_vectorized = vectorizer_split.transform(test['code'])\n",
    "\n",
    "mnb = MultinomialNB().fit(X_train_vectorized, y_train)\n",
    "preds = mnb.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f336c6f-4410-4e5c-830f-7474ba2c49bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'def foo ( bar ) : return bar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480120b4-fb4a-489a-89ad-6b8607bab99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = vectorizer_split.transform([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3075379e-114b-4e6a-8eaa-3a42615fc783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['scala'], dtype='<U10')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c638af53-b8fc-49c6-b867-d6620a1b9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e98688-0e06-4332-8341-79861c6bd022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        ('tfidf', TfidfVectorizer(token_pattern='\\S+')),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c02386fb-dc11-4a47-be13-800470fde8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(token_pattern=&#x27;\\\\S+&#x27;)),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(token_pattern=&#x27;\\\\S+&#x27;)),\n",
       "                (&#x27;clf&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(token_pattern=&#x27;\\\\S+&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer(token_pattern='\\\\S+')),\n",
       "                ('clf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(train['code'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94a1d66d-5442-4b3d-b8a3-82b31114c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.89      0.99      0.93       229\n",
      "         cpp       0.99      0.86      0.92       230\n",
      "         css       0.96      0.99      0.97       220\n",
      "     haskell       0.99      0.98      0.98       221\n",
      "        html       0.96      0.97      0.96       240\n",
      "        java       0.97      0.97      0.97       216\n",
      "  javascript       0.94      0.98      0.96       219\n",
      "         lua       1.00      0.97      0.99       218\n",
      "        objc       1.00      0.97      0.99       243\n",
      "        perl       1.00      0.97      0.98       225\n",
      "         php       0.98      0.95      0.97       237\n",
      "      python       0.97      0.93      0.95       225\n",
      "           r       0.99      0.99      0.99       214\n",
      "        ruby       0.92      0.98      0.95       208\n",
      "       scala       0.97      1.00      0.98       198\n",
      "      sqlite       0.96      0.98      0.97       209\n",
      "       swift       1.00      0.98      0.99       210\n",
      "\n",
      "    accuracy                           0.97      3762\n",
      "   macro avg       0.97      0.97      0.97      3762\n",
      "weighted avg       0.97      0.97      0.97      3762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = pipe.predict(test['code'])\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafcc715-2911-45a4-b59e-e724759b9d81",
   "metadata": {},
   "source": [
    "## Stop words calculation try"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e4d924-77ed-47fd-931b-c14310892607",
   "metadata": {},
   "source": [
    "https://www.researchgate.net/publication/318969652_AN_AUTO-GENERATED_APPROACH_OF_STOP_WORDS_USING_AGGREGATED_ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe31b35-a021-4882-89dc-65abb2a6b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Based on: https://github.com/bnriiitb/autostopwordgen\n",
    "\n",
    "class AutoStopWordsGen:\n",
    "\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"\n",
    "        :param corpus: corpus\n",
    "        \"\"\"\n",
    "        logging.info('initializing the AutoStopwordsGen started')\n",
    "        cv = CountVectorizer(tokenizer=lambda x: x.split())\n",
    "        cvft = cv.fit_transform(corpus)\n",
    "        tfidfcv = TfidfVectorizer(tokenizer=lambda x: x.split())\n",
    "        tfidfcvft = tfidfcv.fit_transform(corpus)\n",
    "        self.tfidfcv=tfidfcv\n",
    "        self.cvft=cvft\n",
    "        logging.info('initializing the AutoStopwordsGen completed')\n",
    "\n",
    "    def get_stopwords(self, top_n=.95, last_n=.1):\n",
    "\n",
    "        \"\"\"\n",
    "        :param top_n: top n percent threshold\n",
    "        :param last_n: last n percent threshold\n",
    "        :return: returns stopwords\n",
    "        \"\"\"\n",
    "        logging.info('generating stopwords started')\n",
    "        word_freq_df = pd.DataFrame({'word': self.tfidfcv.get_feature_names_out(),\n",
    "                                     'frequency':np.asarray(self.cvft.sum(axis=0)).ravel().tolist(),\n",
    "                                     'idf':self.tfidfcv.idf_})\n",
    "        word_freq_df.sort_values(by=['frequency'],ascending = False,inplace=True)\n",
    "\n",
    "        word_freq_df['prob'] = word_freq_df.frequency/word_freq_df.shape[0]\n",
    "        word_freq_df['entropy'] = word_freq_df.prob.apply(lambda x: x*np.log(1/x))\n",
    "        word_freq_df['vp'] = np.power(word_freq_df.prob-word_freq_df.prob.mean(),2)/word_freq_df.shape[0]\n",
    "\n",
    "        stopwords=dict({'frequency':[],'idf':[],'entropy':[],'vp':[]})\n",
    "        cols=['frequency','entropy','vp', 'idf']\n",
    "\n",
    "        for col in cols:\n",
    "            # print(col,' : ',word_freq_df[col].quantile([last_n,top_n]).tolist())\n",
    "            if(col=='frequency'):\n",
    "                top_5_percent=word_freq_df[col].quantile([last_n,top_n]).tolist()[1]\n",
    "                stopwords[col]=word_freq_df[word_freq_df[col]>=top_5_percent].word.tolist()\n",
    "            else:\n",
    "                last_10_percent=word_freq_df[col].quantile([last_n,top_n]).tolist()[0]\n",
    "                stopwords[col]=word_freq_df[word_freq_df[col]<=last_10_percent].word.tolist()\n",
    "\n",
    "        for key in stopwords.keys():\n",
    "            stopwords[key]=set(stopwords[key])\n",
    "            \n",
    "        very_high_aggregation = word_freq_df[word_freq_df.frequency<2].word.tolist()\n",
    "        \n",
    "        very_high_aggregation.extend(list(stopwords['frequency'].intersection(stopwords['entropy']).intersection(stopwords['vp'])))\n",
    "        very_high_aggregation=list(set(very_high_aggregation))\n",
    "        logging.info('# stopwords generated :: '+str(len(very_high_aggregation)))\n",
    "        logging.info('generating stopwords completed')\n",
    "        return very_high_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78f7f34d-227e-4a49-b50d-2bb7f1f23426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 18:52:54,347 : INFO : initializing the AutoStopwordsGen started\n",
      "/home/qnbhd/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "2023-04-13 18:52:55,362 : INFO : initializing the AutoStopwordsGen completed\n"
     ]
    }
   ],
   "source": [
    "asw = AutoStopWordsGen(train['code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70221a1c-b815-47c7-b894-7b63206f456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 18:52:55,425 : INFO : generating stopwords started\n",
      "2023-04-13 18:52:55,605 : INFO : # stopwords generated :: 42950\n",
      "2023-04-13 18:52:55,606 : INFO : generating stopwords completed\n"
     ]
    }
   ],
   "source": [
    "stop_words = asw.get_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a21d341-c1e0-4a60-8c3d-8daaf104320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6f06b19-907b-45b3-bcee-d40f13e029df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qnbhd/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           c       0.93      0.99      0.96       229\n",
      "         cpp       1.00      0.90      0.94       230\n",
      "         css       0.96      0.99      0.97       220\n",
      "     haskell       0.99      0.97      0.98       221\n",
      "        html       0.96      0.94      0.95       240\n",
      "        java       0.97      0.98      0.97       216\n",
      "  javascript       0.96      0.98      0.97       219\n",
      "         lua       0.99      0.97      0.98       218\n",
      "        objc       0.99      0.98      0.98       243\n",
      "        perl       1.00      0.98      0.99       225\n",
      "         php       0.99      0.97      0.98       237\n",
      "      python       0.95      0.94      0.94       225\n",
      "           r       0.98      0.99      0.98       214\n",
      "        ruby       0.93      0.98      0.95       208\n",
      "       scala       0.99      1.00      0.99       198\n",
      "      sqlite       0.96      0.99      0.97       209\n",
      "       swift       1.00      0.98      0.99       210\n",
      "\n",
      "    accuracy                           0.97      3762\n",
      "   macro avg       0.97      0.97      0.97      3762\n",
      "weighted avg       0.97      0.97      0.97      3762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(tokenizer=lambda x: x.split(), stop_words=stop_words)\n",
    "X_train_vectorized = vectorizer.fit_transform(train['code'])\n",
    "X_test_vectorized = vectorizer.transform(test['code'])\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=42).fit(X_train_vectorized, y_train)\n",
    "preds = clf.predict(X_test_vectorized)\n",
    "print(classification_report(y_test, preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1c468-3eef-44e5-a26b-8abd33c94199",
   "metadata": {},
   "source": [
    "From this we can conclude that deleting `54404` words with this algorithm can reduce the number of words in the corpus and the quality will remain virtually unchanged. Therefore, in the future you can try to apply this list of stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d9b4e54-af84-4df0-b654-491a9d8924f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6f40159-9308-4d2e-8437-436ab7597101",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stop-words.json', 'w') as f:\n",
    "    f.write(json.dumps([w.strip() for w in stop_words]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
