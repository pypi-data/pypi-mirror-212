# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
import grpc

import vision_pb2 as vision__pb2


class AIVisionServiceGrpcStub(object):
    """定义服务,用在rpc传输中
    """

    def __init__(self, channel):
        """Constructor.

        Args:
            channel: A grpc.Channel.
        """
        self.trainAndSave = channel.unary_stream(
                '/AIVisionPackage.AIVisionServiceGrpc/trainAndSave',
                request_serializer=vision__pb2.TrainAndSaveRequest.SerializeToString,
                response_deserializer=vision__pb2.TrainAndSaveResponse.FromString,
                )
        self.loadModel = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/loadModel',
                request_serializer=vision__pb2.LoadModelRequest.SerializeToString,
                response_deserializer=vision__pb2.LoadModelResponse.FromString,
                )
        self.setModelPara = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/setModelPara',
                request_serializer=vision__pb2.SetModelParaRequest.SerializeToString,
                response_deserializer=vision__pb2.SetModelParaResponse.FromString,
                )
        self.doModelInference = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/doModelInference',
                request_serializer=vision__pb2.InferenceRequest.SerializeToString,
                response_deserializer=vision__pb2.InferenceResponse.FromString,
                )
        self.releaseModel = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/releaseModel',
                request_serializer=vision__pb2.ReleaseModelRequest.SerializeToString,
                response_deserializer=vision__pb2.ReleaseModelResponse.FromString,
                )
        self.startAutoInference = channel.unary_stream(
                '/AIVisionPackage.AIVisionServiceGrpc/startAutoInference',
                request_serializer=vision__pb2.AutoInferenceRequest.SerializeToString,
                response_deserializer=vision__pb2.InferenceResponse.FromString,
                )
        self.stopAutoInference = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/stopAutoInference',
                request_serializer=vision__pb2.EmptyRequest.SerializeToString,
                response_deserializer=vision__pb2.CommonResponse.FromString,
                )
        self.startPushInferenceResult = channel.unary_stream(
                '/AIVisionPackage.AIVisionServiceGrpc/startPushInferenceResult',
                request_serializer=vision__pb2.EmptyRequest.SerializeToString,
                response_deserializer=vision__pb2.InferenceResponse.FromString,
                )
        self.stopPushInferenceResult = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/stopPushInferenceResult',
                request_serializer=vision__pb2.EmptyRequest.SerializeToString,
                response_deserializer=vision__pb2.CommonResponse.FromString,
                )
        self.getCameraNumber = channel.unary_unary(
                '/AIVisionPackage.AIVisionServiceGrpc/getCameraNumber',
                request_serializer=vision__pb2.EmptyRequest.SerializeToString,
                response_deserializer=vision__pb2.CameraNumberResponse.FromString,
                )


class AIVisionServiceGrpcServicer(object):
    """定义服务,用在rpc传输中
    """

    def trainAndSave(self, request, context):
        """训练模型
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def loadModel(self, request, context):
        """加载模型
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def setModelPara(self, request, context):
        """设置参数
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def doModelInference(self, request, context):
        """推理
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def releaseModel(self, request, context):
        """释放部分模型,当列表为空时表示释放所有模型
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def startAutoInference(self, request, context):
        """开始自动推理
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def stopAutoInference(self, request, context):
        """停止自动推理
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def startPushInferenceResult(self, request, context):
        """使能推理结果上送
        使能之后，每次推理（自动推理，单次推理）后，将结果通过消息上送
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def stopPushInferenceResult(self, request, context):
        """去使能推理结果上送
        去使能之后，推理结果不上送
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')

    def getCameraNumber(self, request, context):
        """摄像头个数查询
        """
        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
        context.set_details('Method not implemented!')
        raise NotImplementedError('Method not implemented!')


def add_AIVisionServiceGrpcServicer_to_server(servicer, server):
    rpc_method_handlers = {
            'trainAndSave': grpc.unary_stream_rpc_method_handler(
                    servicer.trainAndSave,
                    request_deserializer=vision__pb2.TrainAndSaveRequest.FromString,
                    response_serializer=vision__pb2.TrainAndSaveResponse.SerializeToString,
            ),
            'loadModel': grpc.unary_unary_rpc_method_handler(
                    servicer.loadModel,
                    request_deserializer=vision__pb2.LoadModelRequest.FromString,
                    response_serializer=vision__pb2.LoadModelResponse.SerializeToString,
            ),
            'setModelPara': grpc.unary_unary_rpc_method_handler(
                    servicer.setModelPara,
                    request_deserializer=vision__pb2.SetModelParaRequest.FromString,
                    response_serializer=vision__pb2.SetModelParaResponse.SerializeToString,
            ),
            'doModelInference': grpc.unary_unary_rpc_method_handler(
                    servicer.doModelInference,
                    request_deserializer=vision__pb2.InferenceRequest.FromString,
                    response_serializer=vision__pb2.InferenceResponse.SerializeToString,
            ),
            'releaseModel': grpc.unary_unary_rpc_method_handler(
                    servicer.releaseModel,
                    request_deserializer=vision__pb2.ReleaseModelRequest.FromString,
                    response_serializer=vision__pb2.ReleaseModelResponse.SerializeToString,
            ),
            'startAutoInference': grpc.unary_stream_rpc_method_handler(
                    servicer.startAutoInference,
                    request_deserializer=vision__pb2.AutoInferenceRequest.FromString,
                    response_serializer=vision__pb2.InferenceResponse.SerializeToString,
            ),
            'stopAutoInference': grpc.unary_unary_rpc_method_handler(
                    servicer.stopAutoInference,
                    request_deserializer=vision__pb2.EmptyRequest.FromString,
                    response_serializer=vision__pb2.CommonResponse.SerializeToString,
            ),
            'startPushInferenceResult': grpc.unary_stream_rpc_method_handler(
                    servicer.startPushInferenceResult,
                    request_deserializer=vision__pb2.EmptyRequest.FromString,
                    response_serializer=vision__pb2.InferenceResponse.SerializeToString,
            ),
            'stopPushInferenceResult': grpc.unary_unary_rpc_method_handler(
                    servicer.stopPushInferenceResult,
                    request_deserializer=vision__pb2.EmptyRequest.FromString,
                    response_serializer=vision__pb2.CommonResponse.SerializeToString,
            ),
            'getCameraNumber': grpc.unary_unary_rpc_method_handler(
                    servicer.getCameraNumber,
                    request_deserializer=vision__pb2.EmptyRequest.FromString,
                    response_serializer=vision__pb2.CameraNumberResponse.SerializeToString,
            ),
    }
    generic_handler = grpc.method_handlers_generic_handler(
            'AIVisionPackage.AIVisionServiceGrpc', rpc_method_handlers)
    server.add_generic_rpc_handlers((generic_handler,))


 # This class is part of an EXPERIMENTAL API.
class AIVisionServiceGrpc(object):
    """定义服务,用在rpc传输中
    """

    @staticmethod
    def trainAndSave(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(request, target, '/AIVisionPackage.AIVisionServiceGrpc/trainAndSave',
            vision__pb2.TrainAndSaveRequest.SerializeToString,
            vision__pb2.TrainAndSaveResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def loadModel(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/loadModel',
            vision__pb2.LoadModelRequest.SerializeToString,
            vision__pb2.LoadModelResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def setModelPara(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/setModelPara',
            vision__pb2.SetModelParaRequest.SerializeToString,
            vision__pb2.SetModelParaResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def doModelInference(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/doModelInference',
            vision__pb2.InferenceRequest.SerializeToString,
            vision__pb2.InferenceResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def releaseModel(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/releaseModel',
            vision__pb2.ReleaseModelRequest.SerializeToString,
            vision__pb2.ReleaseModelResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def startAutoInference(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(request, target, '/AIVisionPackage.AIVisionServiceGrpc/startAutoInference',
            vision__pb2.AutoInferenceRequest.SerializeToString,
            vision__pb2.InferenceResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def stopAutoInference(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/stopAutoInference',
            vision__pb2.EmptyRequest.SerializeToString,
            vision__pb2.CommonResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def startPushInferenceResult(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_stream(request, target, '/AIVisionPackage.AIVisionServiceGrpc/startPushInferenceResult',
            vision__pb2.EmptyRequest.SerializeToString,
            vision__pb2.InferenceResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def stopPushInferenceResult(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/stopPushInferenceResult',
            vision__pb2.EmptyRequest.SerializeToString,
            vision__pb2.CommonResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)

    @staticmethod
    def getCameraNumber(request,
            target,
            options=(),
            channel_credentials=None,
            call_credentials=None,
            insecure=False,
            compression=None,
            wait_for_ready=None,
            timeout=None,
            metadata=None):
        return grpc.experimental.unary_unary(request, target, '/AIVisionPackage.AIVisionServiceGrpc/getCameraNumber',
            vision__pb2.EmptyRequest.SerializeToString,
            vision__pb2.CameraNumberResponse.FromString,
            options, channel_credentials,
            insecure, call_credentials, compression, wait_for_ready, timeout, metadata)
