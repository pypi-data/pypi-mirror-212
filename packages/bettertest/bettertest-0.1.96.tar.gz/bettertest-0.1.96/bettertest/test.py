from __init__ import BetterTest
import openai 
openai.api_key = "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"
# questions = ['what does a complex QA instance mean?',
#  '<@1098583990618837062> how can I train an instance based off of a websites documentation, without using PDF? could i web scrape the content and then upload that content? i am trying to ask questions based off of a websites documentation, and im not sure how to convert the data from the website easily',
#  '<@1098583990618837062> how can i train an instance based off of a websites documentation?',
#  '<@1098583990618837062> Is there a way to delete data sources once they are uploaded?',
#  'how do I pass chat history using curl <@1098583990618837062>',
#  '<@1098583990618837062> give me as much information you can about testing within berri',
#  '<@1098583990618837062> how do i update instance with json',
#  '<@1098583990618837062> how should I store my chunks?',
#  'give me an example how to upload a file with its directory',
#  '<@1098583990618837062> How do I enter the values for user_email and instance_id into the Berri-chat-fe github repo?',
#  'There is no .env file in the root of the directory.',
#  '<@1098583990618837062> How do I enter the values for user_email and instance_id into the Berri-chatGPT-UI project on github?',
#  '<@1098583990618837062> can berri AI access previous conversations and continue conversations in the context of the use of the Berri AI platform for conversations',
#  '<@1098583990618837062> What are the most common and unusual use of Berri AI to this day?',
#  '<@1098583990618837062> in python, should i use context or history to pass in a previous conversation?',
#  '<@1098583990618837062> is it p-ossible to feed berri past convesations when asking apromt in python?',
#  '<@1098583990618837062> is it p-ossible to feed berri past convesations when asking apromt?',
#  'Has anyone tried integrating berri with webflow and wized backend app builder? Or any onther no code platform?',
#  'what are the requirements for PDF files <@1098583990618837062>',
#  '<@1098583990618837062> I am receiving mail every time when create_app , I dont want mail',
#  '<@1098583990618837062> What does the ai model see the data as? Does it see it as the large corpus of text it is trained on or something else?']
questions = ['what does a complex QA instance mean?',
 '<@1098583990618837062> how can I train an instance based off of a websites documentation, without using PDF? could i web scrape the content and then upload that content? i am trying to ask questions based off of a websites documentation, and im not sure how to convert the data from the website easily',
 '<@1098583990618837062> how can i train an instance based off of a websites documentation?',
'<@1098583990618837062> What does the ai model see the data as? Does it see it as the large corpus of text it is trained on or something else?']

def call_openai(question):
    # # Note: you need to be using OpenAI Python v0.27.0 for the code below to work
    # response = openai.ChatCompletion.create(
    # model="gpt-3.5-turbo",
    # messages=[
    #         {"role": "system", "content": "You are a helpful assistant."},
    #         {"role": "user", "content": question},
    #     ]
    # )
    index = questions.index(question)
    # model_answers = ['A complex QA instance refers to a type of search in which users ask questions that require multiple pieces of context. For example, if a user asks "What is the age of the actress who plays Meg in Family Guy?", the system needs to know both "Who plays Meg in Family Guy?" and "What is Mila Kunis\'s age?" to provide an accurate answer. To handle this, the user question is broken down into sub-components, and the most relevant chunks for each sub-question are found and fed into the chatGPT/GPT-4 model to get the answer.\n  \n  REFERENCES\n Discord Chat; https://docs.berri.ai/api-reference/app_configurations/file_configuration;',
#  "To train an instance based off of a website's documentation without using a PDF, you can scrape the content from the website and then upload it as a data source. You can use web scraping tools such as Beautiful Soup or Scrapy to extract the text from the website and then upload it using the BerriAI API. Once you have uploaded the data source, you can use it to train your instance and ask questions based on the website's documentation. However, please note that web scraping may be subject to legal restrictions, so make sure to check the website's terms of service and consult with a legal professional if necessary.\n  \n  REFERENCES\n Discord Chat;",
#  'To train an instance based off of a website\'s documentation, you can use the "Recursive URLs" feature provided by BerriAI. This feature allows you to recursively parse URLs and extract text data from them, which can then be used to train your instance. \n \n\n Here\'s an example of how you can use this feature:\n \n\n 1. First, create a data source using the "create_data_source" endpoint. You can specify the URL of the website you want to train your instance on as the "data_source" parameter. \n \n\n 2. Next, use the "create_app" endpoint to create an instance of your GPT-4 app. In the payload, specify the "data_source" parameter as the ID of the data source you created in step 1. \n \n\n 3. Finally, use the "finetune_instance" endpoint to fine-tune your instance using the data extracted from the website. You can pass in a list of JSON objects containing context and correct_response attributes to this endpoint. \n \n\n Keep in mind that the quality of the instance you train will depend on the quality of the data you extract from the website. It\'s important to ensure that the data you extract is relevant and accurate.\n  \n  REFERENCES\n Discord Chat;',
#  'As of now there is no way to delete data sources once they are uploaded using the API. We will be adding this feature to our roadmap very soon.\n  \n  REFERENCES\n Discord Chat;',
#  "To pass chat history using curl, you can use the same parameters provided in the JavaScript code. Here's an example curl command:\n \n\n ```\n curl --location --request GET 'https://api.berri.ai/query?user_email=ishaan@berri.ai&instance_id=92232da7-4e9f-45d1-a05b-6a8abd1e9285&query=What%20is%20your%20pricing%3F&model=gpt-3.5-turbo&top_k=5&dynamic_prompt=You%20are%20an%20AI%20sales%20assistant.%20Answer%20all%20questions%20respectfully.%20Your%20company%20charges%20%24500%2Fmo.%20Someone%20from%20Facebook%20is%20asking%20you%20a%20question%2C%20they%20are%20currently%20on%20your%20company%27s%20pricing%20page.%20This%20person%20has%20visited%20the%20website%205%20times.&history=%5B%22hi%22%2C%20%22HELLO%22%2C%20%22how%20are%20you%3F%22%2C%20%22i'm%20well%22%5D'\n ```\n \n\n Make sure to replace the values for `user_email`, `instance_id`, `query`, `model`, `top_k`, `dynamic_prompt`, and `history` with your own values.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/tutorials/js_query_with_history; Discord Chat;",
#  'Sure! BerriAI provides a testing environment for developers to test their chatGPT instances before deploying them to production. This is done through the "POST https://api.berri.ai/test_instance" endpoint. You can pass in a list of JSON objects containing context and expected_response attributes to test your chatGPT instance. Additionally, BerriAI provides a dashboard where you can view the results of your tests and see how well your chatGPT instance is performing. You can find more information about testing in the BerriAI API documentation under the "Testing" section.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/faqs-support/faqs;',
#  'I\'m sorry, but you cannot update an instance with JSON. The "Update your Instance Data" endpoint only allows you to add data sources such as URLs or files to an existing instance. If you want to update the content of your instance, you will need to create a new instance with the updated data.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/endpoint/update_instance;',
#  'Based on the information available, it seems that BerriAI gives you the option to choose where to store your embeddings, including the option to store them in your own database. However, there is no specific information on how to store chunks. I suggest checking the BerriAI API documentation or reaching out to their support team for more information on how to store chunks.\n  \n  REFERENCES\n Discord Chat;',
#  'Sure! Here\'s an example of how to upload a file with its directory using Python:\n \n\n ```python\n import requests\n \n\n template_id = "9a5f0111-4e8b-428d-8fda-863773fe41cd"\n \n\n url = "https://api.berri.ai/create_app"\n \n\n data = {"template_id": template_id, "user_email": "example@berri.ai"}\n \n\n files = {\'data_source\': (\'/path/to/file.pdf\', open(\'/path/to/file.pdf\', \'rb\'))}\n \n\n response = requests.post(url, files=files, data=data)\n \n\n print(response.text)\n \n\n api_endpoint = response.json()["api_endpoint"]\n ```\n \n\n In this example, replace `/path/to/file.pdf` with the actual file path and `example@berri.ai` with your email address. This code will upload the file and its directory to BerriAI and return the API endpoint.\n  \n  REFERENCES\n Discord Chat;',
#  "I'm sorry, but I do not have information about the Berri-chat-fe Github repo. However, you can visit https://docs.berri.ai/ for more information about the BerriAI API and how to use it.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/endpoint/update_instance; Discord Chat;",
#  "I'm sorry, but I'm not sure what specific question you're asking. However, based on the given information, it seems like there is no .env file in the root directory of the project. The .env file is used to store environment variables for the project, so if it's missing, you may need to create one and add any necessary variables.\n  \n  REFERENCES\n Discord Chat;",
#  "I'm sorry, but I'm not sure which specific Berri-chatGPT-UI project on GitHub you are referring to. Can you please provide more information or a link to the project? In general, if you need to enter values for user_email and instance_id in a Berri project, you should look for the relevant code files where these values are used and update them with the appropriate values. If you're unsure about how to do this, you can refer to the project's documentation or reach out to the project's maintainers for assistance.\n  \n  REFERENCES\n Discord Chat;",
#  'Yes, Berri AI can access previous conversations and continue conversations in the context of the use of the Berri AI platform for conversations. You can pass chat history to the API using the "history" parameter in the query endpoint. This allows the chatGPT instance to have context for the conversation and continue the conversation in a more natural way. Additionally, you can use the "dynamic_prompt" parameter to provide additional context for the chatGPT instance to use during the conversation.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/faqs-support/faqs; https://docs.berri.ai/introduction;',
#  "I'm sorry, but I don't have information about the most common and unusual use of Berri AI to this day. However, you can find more information about the scenarios and use cases that Berri AI supports in the API Reference and the Frequently Asked Questions sections of the Berri AI documentation.\n  \n  REFERENCES\n https://docs.berri.ai/introduction; https://docs.berri.ai/api-reference/faqs-support/faqs;",
#  'To pass in a previous conversation in Python, you should use the \'history\' parameter. You can pass in a list of strings containing the conversation history as a JSON string. Here\'s an example code snippet:\n \n\n ```python\n import requests\n import json\n \n\n url = "https://api.berri.ai/query"\n \n\n querystring = {\n  "user_email": "your_email@berri.ai",\n  "instance_id": "your_instance_id",\n  "query": "your_query",\n  "model": "gpt-3.5-turbo",\n  "history": json.dumps(["previous message 1", "previous message 2"])\n }\n \n\n response = requests.get(url, params=querystring)\n \n\n print(response.text)\n ```\n \n\n Make sure to replace \'your_email@berri.ai\', \'your_instance_id\', \'your_query\', and the conversation history with your own values.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/tutorials/js_query_with_history; Discord Chat;',
#  'Yes, it is possible to feed Berri past conversations when asking a prompt in Python. You can do this by passing in the chat history as a parameter in the API call. Here\'s an example of how to do this in Python:\n \n\n ```python\n import requests\n \n\n url = "https://api.berri.ai/query"\n \n\n querystring = {\n  "user_email": "your_email@berri.ai",\n  "instance_id": "your_instance_id",\n  "model": "gpt-3.5-turbo",\n  "top_k": "5",\n  "query": "your_prompt",\n  "history": \'["hi", "hello", "how are you?"]\'\n }\n \n\n response = requests.get(url, params=querystring)\n print(response.json()["response"])\n ```\n \n\n In the above code, you can pass the chat history as a JSON-encoded string in the "history" parameter. The chat history should be a list of strings representing the previous messages in the conversation.\n  \n  REFERENCES\n Discord Chat;',
#  'Yes, it is possible to feed Berri past conversations when asking a prompt. You can pass in the chat history as a parameter in the API call. For example, in the JavaScript code, you can pass in the chat history as an array of strings using the "history" parameter. Here\'s an example:\n \n\n ```\n const chatHistory = ["Hi", "How are you?", "I\'m good, thanks for asking."];\n \n\n fetch(`https://api.berri.ai/query?user_email=your_email&instance_id=your_instance_id&query=Hello&model=gpt-3.5-turbo&top_k=5&history=${JSON.stringify(chatHistory)}`)\n  .then(response => response.json())\n  .then(data => console.log(data));\n ```\n \n\n You can also pass in the chat history as a string in the API call using the "history" parameter. Here\'s an example:\n \n\n ```\n const chatHistory = "Hi\\nHow are you?\\nI\'m good, thanks for asking.";\n \n\n fetch(`https://api.berri.ai/query?user_email=your_email&instance_id=your_instance_id&query=Hello&model=gpt-3.5-turbo&top_k=5&history=${encodeURIComponent(chatHistory)}`)\n  .then(response => response.json())\n  .then(data => console.log(data));\n ```\n \n\n Note that you need to encode the chat history string using the "encodeURIComponent" function before passing it as a parameter in the API call.\n  \n  REFERENCES\n Discord Chat;',
#  "I'm sorry, but I do not have information about integrating Berri with Webflow or Wized backend app builder. However, you can try embedding your Berri app into your website using the instructions provided in the BerriAI API documentation. If you encounter any issues, feel free to reach out to the BerriAI support team at krrish@berri.ai.\n  \n  REFERENCES\n https://docs.berri.ai/api-reference/tutorials/website_embed; Discord Chat;",
#  'According to the "Getting Started" document, PDF files are one of the data sources that can be used with BerriAI. The document states that to use a PDF file, you need to ensure that you are reading the file and sending its contents. This works for PDF, DOC, TXT, CSV, and PPTX files. Additionally, the document provides an example curl command and code snippets in Python, JavaScript, and Node.js for uploading a PDF file as a data source.\n  \n  REFERENCES\n Discord Chat;',
#  'To stop receiving emails when creating an app using the BerriAI API, you can remove your email address from the "user_email" parameter in the API call. This parameter is used to send you an email with the API endpoint and other details about the app you created. If you remove your email address from this parameter, you will not receive any emails. Here\'s an example curl command without the "user_email" parameter:\n \n\n ```\n curl --location --request POST \'https://api.berri.ai/create_app\' \\\n --form \'template_id="9a5f0111-4e8b-428d-8fda-863773fe41cd"\' \\\n --form \'data_source=@/Users/krrishdholakia/Downloads/quizlet_wa_test_1.pdf\'\n ```\n \n\n Note that removing the "user_email" parameter will not affect the functionality of the API call or the app you create.\n  \n  REFERENCES\n Discord Chat;',
#  'Hello <@1098583990618837062>, according to the BerriAI API documentation, the AI model sees the data as embeddings, which are numerical representations of the text. These embeddings are generated using a pre-trained language model, such as GPT-3, and are used to make predictions and generate responses. The model does not see the data as the large corpus of text it is trained on, but rather as a set of numerical vectors that represent the semantic meaning of the text.\n  \n  REFERENCES\n Discord Chat;']
#     print("bettertest: testing if this works")
    model_answers = ['A complex QA instance refers to a type of search in which users ask questions that require multiple pieces of context. For example, if a user asks "What is the age of the actress who plays Meg in Family Guy?", the system needs to know both "Who plays Meg in Family Guy?" and "What is Mila Kunis\'s age?" to provide an accurate answer. To handle this, the user question is broken down into sub-components, and the most relevant chunks for each sub-question are found and fed into the chatGPT/GPT-4 model to get the answer.\n  \n  REFERENCES\n Discord Chat; https://docs.berri.ai/api-reference/app_configurations/file_configuration;',
 "To train an instance based off of a website's documentation without using a PDF, you can scrape the content from the website and then upload it as a data source. You can use web scraping tools such as Beautiful Soup or Scrapy to extract the text from the website and then upload it using the BerriAI API. Once you have uploaded the data source, you can use it to train your instance and ask questions based on the website's documentation. However, please note that web scraping may be subject to legal restrictions, so make sure to check the website's terms of service and consult with a legal professional if necessary.\n  \n  REFERENCES\n Discord Chat;",
 'To train an instance based off of a website\'s documentation, you can use the "Recursive URLs" feature provided by BerriAI. This feature allows you to recursively parse URLs and extract text data from them, which can then be used to train your instance. \n \n\n Here\'s an example of how you can use this feature:\n \n\n 1. First, create a data source using the "create_data_source" endpoint. You can specify the URL of the website you want to train your instance on as the "data_source" parameter. \n \n\n 2. Next, use the "create_app" endpoint to create an instance of your GPT-4 app. In the payload, specify the "data_source" parameter as the ID of the data source you created in step 1. \n \n\n 3. Finally, use the "finetune_instance" endpoint to fine-tune your instance using the data extracted from the website. You can pass in a list of JSON objects containing context and correct_response attributes to this endpoint. \n \n\n Keep in mind that the quality of the instance you train will depend on the quality of the data you extract from the website. It\'s important to ensure that the data you extract is relevant and accurate.\n  \n  REFERENCES\n Discord Chat;',
 'Hello <@1098583990618837062>, according to the BerriAI API documentation, the AI model sees the data as embeddings, which are numerical representations of the text. These embeddings are generated using a pre-trained language model, such as GPT-3, and are used to make predictions and generate responses. The model does not see the data as the large corpus of text it is trained on, but rather as a set of numerical vectors that represent the semantic meaning of the text.\n  \n  REFERENCES\n Discord Chat;']
    print("bettertest: testing if this works")
    return model_answers[index]

if __name__ == '__main__':
#     answers = ['Sometimes users ask questions that require multiple pieces of context (e.g. What is the age of the actress who plays Meg in Family Guy? -> This requires us to know - Who plays Meg in Family Guy? Mila Kunis + What is Mila Kunis’s age?). To tackle this, we first run the user question through chatGPT, and have it break down that question into sub-components (as seen in the previous example) -> Find the most relevant chunks for each sub-question -> Feed that into chatGPT/GPT-4/whichever model you chose to get the answer to the users question.',
#  "You can either create an app with an input_url this way you won't need to scrape the website https://docs.berri.ai/api-reference/endpoint/create_app if this does not work you can also manually scrape the website yourself and create an instance with raw text by passing in JSON chunks to berri",
#  "You can either create an app with an input_url this way you won't need to scrape the website https://docs.berri.ai/api-reference/endpoint/create_app if this does not work you can also manually scrape the website yourself and create an instance with raw text by passing in JSON chunks to berri",
#  'There is no way to delete data sources once they are uploaded using the API. We will be adding this feature to our roadmap very soon',
#  'Here is an example of passing chat history using curl: curl -X GET "https://api.berri.ai/query?user_email=ishaan@berri.ai&instance_id=92232da7-4e9f-45d1-a05b-6a8abd1e9285&query=What%20is%20your%20pricing%3F&model=gpt-3.5-turbo&top_k=5&dynamic_prompt=You%20are%20an%20AI%20sales%20assistant.%20Answer%20all%20questions%20respectfully.%20Your%20company%20charges%20%24500%2Fmo.%20Someone%20from%20Facebook%20is%20asking%20you%20a%20question%2C%20they%20are%20currently%20on%20your%20company%27s%20pricing%20page.%20This%20person%20has%20visited%20the%20website%205%20times.&history=%5B%22hi%22%2C%20%22HELLO%22%2C%20%22how%20are%20you%3F%22%2C%20%22i%27m%20well%22%5D"',
#  'You can test your berri instances using https://api.berri.ai/eval. You can pass your berri instance a csv file of your test questions under the column "Questions" and berri will run though your test questions and display the answers',
#  'You cannot update an instance with JSON',
#  'You can create a list of chunks you want to create your berri app with, you then need to create a JSON obj from your chunks and create an app. Here is a code sample for this: url = "https://api.berri.ai/create_app"\n data = {"user_email": <your_email>, "data_source": json.dumps(text_list)}\n response = requests.post(url, data=data)\n response.text',
#  'Here is an example of uploading a file with it\'s directory: import requests\n \n\n template_id = "9a5f0111-4e8b-428d-8fda-863773fe41cd"\n \n\n url = "https://api.berri.ai/create_app"\n \n\n data = {"template_id": template_id, "user_email": "krrish@berri.ai"}\n \n\n files = {\'data_source\': open(\'quizlet_wa_test_1.pdf\', \'rb\')}\n \n\n response = requests.post(url, files=files, data=data)\n \n\n print(response.text)\n \n\n api_endpoint = response.json()["api_endpoint"]',
#  "I'm sorry I dont have any information about the Berri-chat-fe Github Repo",
#  "I'm sorry I dont have any information about the Berri-chat-fe Github Repo",
#  "I'm sorry I dont have any information about the Berri-chat-fe Github Repo",
#  'Yes, you can do this using the history param on the query endpoint: https://docs.berri.ai/api-reference/endpoint/query',
#  'Berri can be used for building chatbots for customer support, education tutors, content classification',
#  'You should use the history param in python to pass in previous conversation, here is an example',
#  "Yes, it's possible to feed Berri past conversations when asking a prompt. This can be achieved by passing the conversation history",
#  "Yes, it's possible to feed Berri past conversations when asking a prompt. This can be achieved by passing the conversation history",
#  'Hello, to the best of my information I have not seen anyone implement berri with webflow or wized',
#  'There are no requirements for PDF files. Are you running into any problems ?',
#  "We're currently not able to help with this request & don't have support for this. @ishaan flagging for your attention",
#  "Berri ingests your data, chunks it, creates embeddings. When user's ask questions, berri does a similarity search and retrieves the most similar chunks to answer the questions. These chunks are then fed into the llm to answer the question"]
    
    answers = ['Sometimes users ask questions that require multiple pieces of context (e.g. What is the age of the actress who plays Meg in Family Guy? -> This requires us to know - Who plays Meg in Family Guy? Mila Kunis + What is Mila Kunis’s age?). To tackle this, we first run the user question through chatGPT, and have it break down that question into sub-components (as seen in the previous example) -> Find the most relevant chunks for each sub-question -> Feed that into chatGPT/GPT-4/whichever model you chose to get the answer to the users question.',
 "You can either create an app with an input_url this way you won't need to scrape the website https://docs.berri.ai/api-reference/endpoint/create_app if this does not work you can also manually scrape the website yourself and create an instance with raw text by passing in JSON chunks to berri",
 "You can either create an app with an input_url this way you won't need to scrape the website https://docs.berri.ai/api-reference/endpoint/create_app if this does not work you can also manually scrape the website yourself and create an instance with raw text by passing in JSON chunks to berri",
 "Berri ingests your data, chunks it, creates embeddings. When user's ask questions, berri does a similarity search and retrieves the most similar chunks to answer the questions. These chunks are then fed into the llm to answer the question"]

    bt = BetterTest("krrish@berri.ai", "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")
    
    bt.eval(questions, answers, call_openai)