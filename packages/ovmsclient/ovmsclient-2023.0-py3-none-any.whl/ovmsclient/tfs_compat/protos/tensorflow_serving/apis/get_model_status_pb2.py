# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: ovmsclient/tfs_compat/protos/tensorflow_serving/apis/get_model_status.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from ovmsclient.tfs_compat.protos.tensorflow_serving.apis import model_pb2 as ovmsclient_dot_tfs__compat_dot_protos_dot_tensorflow__serving_dot_apis_dot_model__pb2
from ovmsclient.tfs_compat.protos.tensorflow_serving.util import status_pb2 as ovmsclient_dot_tfs__compat_dot_protos_dot_tensorflow__serving_dot_util_dot_status__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\nKovmsclient/tfs_compat/protos/tensorflow_serving/apis/get_model_status.proto\x12\x12ovmsclient.serving\x1a@ovmsclient/tfs_compat/protos/tensorflow_serving/apis/model.proto\x1a\x41ovmsclient/tfs_compat/protos/tensorflow_serving/util/status.proto\"J\n\x15GetModelStatusRequest\x12\x31\n\nmodel_spec\x18\x01 \x01(\x0b\x32\x1d.ovmsclient.serving.ModelSpec\"\xe8\x01\n\x12ModelVersionStatus\x12\x0f\n\x07version\x18\x01 \x01(\x03\x12;\n\x05state\x18\x02 \x01(\x0e\x32,.ovmsclient.serving.ModelVersionStatus.State\x12/\n\x06status\x18\x03 \x01(\x0b\x32\x1f.ovmsclient.serving.StatusProto\"S\n\x05State\x12\x0b\n\x07UNKNOWN\x10\x00\x12\t\n\x05START\x10\n\x12\x0b\n\x07LOADING\x10\x14\x12\r\n\tAVAILABLE\x10\x1e\x12\r\n\tUNLOADING\x10(\x12\x07\n\x03\x45ND\x10\x32\"t\n\x16GetModelStatusResponse\x12Z\n\x14model_version_status\x18\x01 \x03(\x0b\x32&.ovmsclient.serving.ModelVersionStatusR\x14model_version_statusB\x03\xf8\x01\x01\x62\x06proto3')



_GETMODELSTATUSREQUEST = DESCRIPTOR.message_types_by_name['GetModelStatusRequest']
_MODELVERSIONSTATUS = DESCRIPTOR.message_types_by_name['ModelVersionStatus']
_GETMODELSTATUSRESPONSE = DESCRIPTOR.message_types_by_name['GetModelStatusResponse']
_MODELVERSIONSTATUS_STATE = _MODELVERSIONSTATUS.enum_types_by_name['State']
GetModelStatusRequest = _reflection.GeneratedProtocolMessageType('GetModelStatusRequest', (_message.Message,), {
  'DESCRIPTOR' : _GETMODELSTATUSREQUEST,
  '__module__' : 'ovmsclient.tfs_compat.protos.tensorflow_serving.apis.get_model_status_pb2'
  # @@protoc_insertion_point(class_scope:ovmsclient.serving.GetModelStatusRequest)
  })
_sym_db.RegisterMessage(GetModelStatusRequest)

ModelVersionStatus = _reflection.GeneratedProtocolMessageType('ModelVersionStatus', (_message.Message,), {
  'DESCRIPTOR' : _MODELVERSIONSTATUS,
  '__module__' : 'ovmsclient.tfs_compat.protos.tensorflow_serving.apis.get_model_status_pb2'
  # @@protoc_insertion_point(class_scope:ovmsclient.serving.ModelVersionStatus)
  })
_sym_db.RegisterMessage(ModelVersionStatus)

GetModelStatusResponse = _reflection.GeneratedProtocolMessageType('GetModelStatusResponse', (_message.Message,), {
  'DESCRIPTOR' : _GETMODELSTATUSRESPONSE,
  '__module__' : 'ovmsclient.tfs_compat.protos.tensorflow_serving.apis.get_model_status_pb2'
  # @@protoc_insertion_point(class_scope:ovmsclient.serving.GetModelStatusResponse)
  })
_sym_db.RegisterMessage(GetModelStatusResponse)

if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\370\001\001'
  _GETMODELSTATUSREQUEST._serialized_start=232
  _GETMODELSTATUSREQUEST._serialized_end=306
  _MODELVERSIONSTATUS._serialized_start=309
  _MODELVERSIONSTATUS._serialized_end=541
  _MODELVERSIONSTATUS_STATE._serialized_start=458
  _MODELVERSIONSTATUS_STATE._serialized_end=541
  _GETMODELSTATUSRESPONSE._serialized_start=543
  _GETMODELSTATUSRESPONSE._serialized_end=659
# @@protoc_insertion_point(module_scope)
